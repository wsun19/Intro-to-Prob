---
title: Intro Prob Lecture Notes
author:
    - William Sun
date:
    - March 13, 2017
geometry: margin=3cm
header-includes:
    - \usepackage{setspace}
    - \doublespacing
---
# Continuous Random Variables
- A random variable $X$ is called *continuous* if it possesses a cumulative distribution function which is a continuous function on the real line.
    - Reminder: CDF is $F_X(x) = P(X \leq x)$
- Let $x \in \mathbb{R}$. Then for $h > 0$,
\begin{align*}
P(x - h < X \leq x) &= P(X \leq x) - P(X \leq x - h) \\
&= F_X(x) - F_X(x - h) \\
& \text{Approaches 0 as h approaches 0}
\end{align*}
- Therefore, $P(X = x) = 0$.
- But
$$\mathbf{\frac{P(x - h < X \leq x)}{h} = \frac{F_X(x) - F_X(x - h)}{h}} \rightarrow \text{(If this difference quotient converges) } F_X'(x) = f_X(x) \geq 0$$
- Bold value is probability mass per unit length, or a probability "density"
$$P(-\infty < X \leq x) = F_X(x) = \int\limits_{-\infty}^x f(u)du$$
$$ \text{As } x \rightarrow \infty, 1 = \int\limits_{-\infty}^{\infty} f_X(u)du$$
- A probability desnity function (pdf) is any function f such that
    - $f: \mathbb{R} \rightarrow \mathbb{R}, f(x) \geq 0 \forall x \in \mathbb{R}$
    - $\int\limits_{-\infty}^{\infty} f(x)dx = 1$
- To compute probability mass, $P(a < X \leq b) := \int\limits_a^b f(x)dx$
- Example: $f(x) = x^2$ on $0 \leq x \leq 2$, $f(x) = 0$ elsewhere
    - Not a pdf.
    \begin{align*}
    \int\limits_{-\infty}^{\infty}f(x)dx  &= \int\limits_{-\infty}^{0}0 dx + \int\limits_{0}^{2}x^2 dx + \int\limits_{2}^{\infty}0 dx \\
    &= \frac{x^3}{3}\Big|_0^2 \\
    &= \frac{8}{3}
    \end{align*}
    - However, we can normalize the function to $\tilde{f}$, so that the value from 0 to 2 to $\frac{3x^2}{8}$. $\tilde{f}$ would integrate to 1, so that would be a pdf
- Suppose $X$ has pdf $\tilde{f}$. Compute
    \begin{align*}
        P(X > \frac{1}{2}) &= \int\limits_{\frac{1}{2}}^{\infty} \tilde{f}(u)du \\
        &= \int\limits_{\frac{1}{2}}^{2} \tilde{f}(u)du \\
        &= \int\limits_{\frac{1}{2}}^{2} \frac{3u^2}{8}du \\
        &= \frac{u^3}{8}\Big|_{\frac{1}{2}}^2 \\
        &= 1 - \frac{1}{64} \\
        &= \frac{63}{64}
    \end{align*}

# Expected Value of Continuous Variables
- When $f_X(x)$ is the pdf of $X$.
$$E(X) = \int\limits_{-\infty}^{\infty}xf_X(x)dx$$
    - This will exist when $\int\limits_{-\infty}^{\infty} \lvert x \rvert f_X(x)dx < \infty$
    - The Cauchy pdf will *not* have an expected value
        - $f(x) \frac{1}{\pi (1 x^2)}$ for $-\infty < x < \infty$
- Exercise:
\begin{align*}
E(X) &= \int\limits_0^2 x \cdot \frac{3}{8}x^2 dx \\
&= \frac{3}{8} \cdot \frac{x^4}{4}\Big|_0^2 \\
&= \frac{3 \cdot 16}{32} \\
&= \frac{3}{2}
\end{align*}
- Example: $X \sim$ uniform[0, 1]
    - $f(x) = 1$ for $0 \leq x \leq 1$
    - $f(x) = 0$ elsewhere.
    - Expectation is $\frac{1}{2}$ by inspection
    \begin{align*}
    E(X) &= \int\limits_0^1 x dx \\
    &= \frac{x^2}{2}\Big|_0^1 \\
    &= \frac{1}{2}
    \end{align*}
    - And
    \begin{align*}
    E(X^2) &= \int\limits_0^1 x^2 dx \\
    &= \frac{x^3}{3}\Big|_0^1 \\
    &= \frac{1}{3}
    \end{align*}
    But we haven't proven this yet!
    - Digression: Let's show the pdf for $Y = X^2$, $E(Y) = \int y f_Y(y) dy$
    \begin{align*}
    F_Y(y) &= P(Y \leq y) \\
    &= P(X^2 \leq y) \\
    &= (\text{Must assume } y \geq 0 )\\
    &= P(\lvert X \rvert \leq \sqrt{y}) \\
    &= P(X \leq \sqrt{y}) \\
    &= \int\limits_0^{\sqrt{y}}f(x) dx
    \end{align*}
    1 if $\sqrt{y} > 1$, $\sqrt{y}$ if $0 \leq \sqrt{y} \leq 1$, 0 if $\sqrt{y} < 0$
    - So, $f_Y(y)$ is 0 if $y > 1$, $\frac{1}{2\sqrt{y}}$ if $0 < y \leq 1$, 0 if $y \leq 0$.
    \begin{align*}
    E(X^2) = E(Y) &= \int\limits_0^1 y \cdot \frac{1}{2 y^{\frac{1}{2}}} dy \\
    &= \frac{1}{2} \int\limits_0^1 y^{\frac{1}{2}} dy \\
    &= \frac{1}{3}y^{\frac{3}{2}}\Big|_0^1 \\
    &= \frac{1}{3}
    \end{align*}
