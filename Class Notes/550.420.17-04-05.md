---
title: Intro Prob Lecture Notes
author:
    - William Sun
date:
    - April 5, 2017
geometry: margin=3cm
header-includes:
    - \usepackage{setspace}
    - \doublespacing
---
# Sum of Random Variables
- Suppose $X, Y$ are jointly discrete with known join pmf. To find the pmf of the sum $X + Y$:
	- Naive approach: $P(X + Y = u) = \sum\limits_{x + y = u}P(X = x, Y = y)$
	- Better approach: Partition it into all of the possible values of $X$: 
	- $$\sum\limits_x P(X = x, X + Y = u) \rightarrow \sum\limits_x P(X = x, Y = u - x)$$
		- and, if $X, Y$ are independent, then $$P(X + Y = u) = \sum\limits_x P(X = x)P(Y = u - x)$$
			- This is the *Convolution formula*
		- If, further, $X \geq 0, Y \geq 0$ and each are integer-valued, then 
		- $$P(X + Y = u) = \sum\limits_{x = 0}^u P(X = x)P(Y = u - x)$$
- Examples: Let $X \sim$ binomial($n, p$), $Y \sim$ binomial($m, p$) and $X, Y$ independent. Let $u \in \{0, 1, 2, \dots, m + n\}$
	- The distribution of the sum is:
	\begin{align*}
	P(X + Y = u) &= \sum\limits_{x = 0}^u \binom{n}{x} p^x(1 - p)^{n - x} \binom{m}{u - x}p^{u - x}(1 - p)^{m - u + x} \\
	&= p^u(1 - p)^{n + m - u} \sum\limits_{x = 0}^u \binom{n}{x} \binom{m}{u - x} \\
	&= \binom{n + m}{u} p^u(1 - p)^{n + m - u} u = 0, 1, 2, \dots, n + m \sim \text{ binomial}(n + m, p)
	\end{align*}
	- Now, as another example, suppose $X + Y = k$ for some known $k$
		- The distribution of $P(X = x) \vert X + Y = k)$ is
		\begin{align*}
		P(X = x \vert X + Y = k) &= \frac{P(X = x, X + Y = k)}{P(X + Y = k)} \\
		&= \frac{P(X = x, Y = k - x)}{P(X + Y = k)} \\
		&= \frac{P(X = x)P(k - x)}{P(X + Y = k)} \\
		&= \frac{\binom{n}{x}p^x(1 - p)^{n - x} \binom{m}{k - x}p^{k - x}(1 - p)^{m - k + x}}{\binom{n + m}{u} p^u(1 - p)^{n + m - k}} \\
		&= \frac{\binom{n}{x} \binom{m}{k - x}}{\binom{n + m}{k}}
		\end{align*}
- $X, Y$ jointly continuous with joint pdf $F(x, y)$. Find pdf of $X + Y$.
\begin{align*}
F_{X + Y}(u) &= P(X + Y \leq u) \\
&= \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{u - y} f(x, y) dxdy \\
f_{X + Y}(u) &= \frac{d}{du}(F_{X + Y}(u)) \\
&= \int\limits_{-\infty}^{\infty} f(u - y, y) dy \text{ or } \int\limits_{-\infty}^{\infty} f(x, u - x) dx
\end{align*}
- If $X, Y$ are independent
	- $$f_{X + Y}(u) = \int\limits_{-\infty}^{\infty} f_X(x)f_Y(u - x) dx$$
		- *Convolution integral*
	- If $X \geq 0, Y \geq 0$ then $$f_{X + Y}(u) = \int\limits_0^u f_X(x) f_Y(u - x) dx$$
- Suppose $X \sim$ Gamma($\alpha_1, \beta$), $Y \sim$ Gamma($\alpha_2, \beta$) independent.
\begin{align*}
	f_{X + Y}(u) &= \int\limits_0^u \frac{x^{\alpha_1 - 1}e^{-\frac{x}{\beta}}}{\beta^{\alpha_1}\Gamma(\alpha_1)} \cdot \frac{(u - x)^{\alpha_2 - 1}e^{-\frac{(u - x)}{\beta}}}{\beta^{\alpha_2}\Gamma(\alpha_2)} \\
	&= \frac{e^{-\frac{u}{\beta}}}{\beta^{\alpha_1 + \alpha_2}\Gamma(\alpha_1) \Gamma(\alpha_2)} \int\limits_0^u x^{\alpha_1 - 1} (u - x)^{\alpha_2 - 1} dx \\
	& \text{Let } x = uy, 0 < y < 1, dx = udy \\
	&= \frac{e^{-\frac{u}{\beta}}}{\beta^{\alpha_1 + \alpha_2} \Gamma(\alpha_1) \Gamma(\alpha_2)} \int\limits_0^1(uy)^{\alpha_1 - 1} (u(1 - y))^{\alpha_2 - 1} u dy \\
	&= \frac{u^{\alpha_1 + \alpha_2 - 1} e^{-\frac{u}{\beta}}}{\beta^{\alpha_1 + \alpha_2} \Gamma(\alpha_1) \Gamma(\alpha_2)} \int\limits_0^1 y^{\alpha_1 - 1} (1 - y)^{\alpha_2 - 1} dy \\
	&= \frac{u^{\alpha_1 + \alpha_2 - 1} e^{-\frac{u}{\beta}}}{\beta^{\alpha_1 + \alpha_2} \Gamma(\alpha_1 + \alpha_2)} \sim \text{ Gamma}(\alpha_1 + \alpha_2, \beta)
\end{align*}
	- *Jacobian method*

# Ordered Statistics
- $X_1, X_2 \dots X_n \sim$ independent, countinuous random variables all having the same distribution (iidf)
	- $X_{(1)}$ = smallest among $X_1, X_2 \dots X_n$
	- $\vdots$
	- $X_{(j)} = j$th smallest among $X_1, X_2 \dots X_n$
	- $\vdots$
	- $X_{(n)}$ is the largest
	- Example: $n = 3$, $x_1 \approx .38, x_2 \approx .214, x_3 \approx .938)$ then $X_{(1)} = x_2, X_{(2)} = x_1, X_{(3)} = x_3$
	