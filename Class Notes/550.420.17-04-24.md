---
title: Intro Prob Lecture Notes
author:
    - William Sun
date:
    - April 24, 2017
geometry: margin=3cm
header-includes:
    - \usepackage{setspace}
    - \doublespacing
---
- Deal 5 cards from a deck of 52. Let $X$ count the number of different suits in the hand. Compute $E(X)$.
	- One way: try to first find $P(X = 1) \Big(\frac{4\binom{13}{5}}{\binom{52}{5}} \Big)$, $P(X = 2)$ etc
	- Other way: Define $X_i = 
	\begin{cases}
		1 & \text{if at least one card of suit i belongs to the hand} \\
		0 & \text{otherwise}
	\end{cases}$
		- so that $X = \sum\limits_{i = 1}^4 X_i$, then 
		-
		\begin{align*}
			E(X) &= \sum\limits_{i = 1}^4 E(X_i) \\
			&= \sum\limits_{i = 1}^4 P( \geq 1 \text{ card of suit } i) \\
			&= \sum\limits_{i = 1}^4 1 - P(\text{no card of suit } i) \\
			&= \sum\limits_{i = 1}^4 (1 - \frac{\binom{13}{0} \binom{39}{5}}{\binom{52}{5}}) \\
			&= 4(1 - \frac{\binom{39}{5}}{\binom{52}{5}}) \\
			& \approx 3.11
		\end{align*}
- $n$ people with $n$ hats. Each randomly selects a hat. Let $X$ = number of people that select their own hat. Compute $E(X)$ and $Var(X)$
	- Define $X_i = 
	\begin{cases}
		1 & \text{if person i selects their own hat} \\
		0 & \text{otherwise}
	\end{cases}$
	- $X = \sum\limits_{i = 1}^n X_i$
	-
	\begin{align*}
		E(X) &= \sum\limits_{i = 1}^n P(X_i = 1) \\
		&= \sum\limits_{i = 1}^n \frac{1}{n} \\
		&= 1
	\end{align*}
	-
	\begin{align*}
		Cov(X_i, X_j) &= E(X_i X_j) - E(X_i)E(X_j) \\
		&= P(X_i = 1, X_j = 1) - \frac{1}{n} \cdot \frac{1}{n} \\
		&= \frac{1}{n(n - 1)} - \frac{1}{n^2} \\
		&= \frac{1}{n^2(n - 1)} \\
		Var(X) &= Var(\sum\limits_{i = 1}^n X_i) \\
		&= \sum\limits_{i = 1}^n Var(X_i) + 2 \sum\limits_{1 \leq i < j \leq n} Cov(X_i, X_j)\\
		&= n \cdot (\frac{1}{n} \cdot (1 - \frac{1}{n})) + 2 \Big( \frac{n(n - 1)}{2} \Big) \cdot \frac{1}{n^2(n - 1)} \\
		&= 1
	\end{align*}
		- Note: Covariance is positive. Makes a little sense since, if person $i$ gets their own hat, person $j$ is slightly more likely to get their own hat 

# Conditional Expectation
- Discrete $$E(X | Y = y) = \sum\limits_x x P(X = x | Y = y)$$ 
- Continuous $$E(X | Y = y) = \int\limits_{-\infty}^{\infty} x f_{X | Y} (x | y) dx$$
- Remember:
	1) $E(X | Y = y)$ is a function of $y$
	2) If $Y$ is independent of $X$, $E(X | Y = y) = E(X)$
- Ex:
	-
	\begin{center}
		\begin{tabular}{ | c | c | c | c | c |}
		 \hline
		 & x = 1 & x = 2 & x = 3 & \\
		 \hline
		 y = 1 & .1 & 0 & .2 & .3\\ 
		 y = 2 & .1 & .1 & 0 & .2\\  
		 y = 3 & .1 & .2 & .1 & .4\\
		 y = 4 & 0 & .1 & 0 & .1 \\
		 \hline
		 & .3 & .4 & .3 & \\
		 \hline
		\end{tabular}
	\end{center}
	- Compute:
		- $E(X | Y = 1) = 1(1/3) + 2(0/3) + 3(2/3) = 7/3$
		- $E(X | Y = 2) = 1(1/2) + 2(1/2) + 3(0/2) = 3/2$
		- $E(X | Y = 3) = 1(1/4) + 2(2/4) + 3(1/4) = 2$
		- $E(X | Y = 4) = 1(0) + 2(1) + 3(0) = 2$
			- $X$ "degenerates" when $Y = 4$ since $X$ can only have one value
- Notation: 
	- $E(X | Y) = g(Y)$ so that when $Y = y$, $E(X | Y) = E(X | Y = y)$
- Law of Total Expectation (a.k.a. Law of Total Probability):
	- $E(E(X | Y)) = E(X)$ for any $Y$
- Ex: $N$ = number of customers that enter store, $X_i$ = amount of money spent by customer $i$
	- Assumption: $N, X_1, X_2, \dots X_n$ independent
	- $S = \sum\limits_{i = 1}^N X_i$ represents the total sales
	- $E(S)$?
		-
		\begin{align*}
			E(\sum\limits_{i = 1}^N X_i | N = n) &= E(\sum\limits_{i = 1}^n X_i | N = n) \\
			&= E(\sum\limits_{i = 1}^N X_i) \\
			&= \sum\limits_{i = 1}^N E(X_i) \\
			&= n \mu_X \\
			E(S) &= E(\sum\limits_{i = 1}^N X_i) \\
			& \text{Using the above property, and Y = N} \\
			&= E\Big(E(\sum\limits_{i = 1}^N X_i | N)\Big) \\
			&= E(N \mu_x) \\
			&= \mu_x E(N) \\
			&= \mu_x \mu_N
		\end{align*}