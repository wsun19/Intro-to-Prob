---
title: Intro Prob Lecture Notes
author:
    - William Sun
date:
    - March 31, 2017
geometry: margin=3cm
header-includes:
    - \usepackage{setspace}
    - \doublespacing
---
- Suppose $X, Y$ are jointly continuous with joint pdf
- $f(x, y) = xy$ for $0 \leq x \leq 2, 0 \leq y \leq 1$, 0 elsewhere
	- Show that this is a joint pdf
		- When $(x, y) \in \mathbf{(0, 2) \times (0, 1)}$ we have, in particular, that $x > 0, y > 0$ Therefore, $f(x, y) = xy > 0$ in this part of the domain.
			- The bolded is the essential domain, or $supp(f)$
		- Furthermore, $f(x, y) = 0$ for $(x, y) \not\in (0, 2) \times (0, 1)$.
		- Therefore, $f(x, y) \geq 0$ $\forall$ $x, y \in \mathbb{R}$
		-
		\begin{align*}
			\int\limits_0^1 \int\limits_0^2 xy dx dy &= \int\limits_0^1 (\frac{x^2y}{2}\Big|_{x = 0}^{x = 2}) dy\\
			&= \int\limits_0^1 2y dy \\
			&= y^2 \Big|_0^1 \\
			&= 1
		\end{align*}
		- So, the total area is also 1
	- Compute $P(X \leq Y)$
		-
		\begin{align*}
			P(X \leq Y) &= \int\int\limits_R f(x, y) dA \\
			&= \int\limits_0^1 \int\limits_0^y xy dx dy \\
			&= \int\limits_0^1 (\frac{x^2y}{2}\Big|_{x = 0}^{x = y}) dy \\
			&= \int\limits_0^1 \frac{y^3}{2} dy \\
			&= \frac{y^4}{8}\Big|_{y = 0}^{y = 1} \\
			&= \frac{1}{8}
		\end{align*}
- The marginal pdf of $X$
	- $f_X(x) = \int\limits_{-\infty}^{\infty} f(x, y) dy$
	- and the marginal pdf of Y 
	- $f_Y(y) = \int\limits_{-\infty}^{\infty} f(x, y) dx$
- $f_X(x) = 0$ when $x \not\in (0, 2)$
- When $x \in (0, 2)$
-
\begin{align*}
	f_X(x) &= \int\limits_{-\infty}^{\infty} f(x, y) dy \\
	&= \int\limits_{-\infty}^{0} 0 dy + \int\limits_{0}^{1} xy dy + \int\limits_{1}^{\infty} 0 dy \\
	&= \frac{x}{2}
\end{align*}
- Exercise: Show $f_Y(y) = 2y$ for $0 < y < 1$, 0 otherwise
- Aside: comments on *marginal pdf*
	- If function is $f(x_1, x_2, x_3, x_4, x_5)$, $f_{x_1}(x_1) = \int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty} f(x_1, x_2, x_3, x_4, x_5) dx_2 dx_3 dx_4 dx_5$
		- Also extends to multivariate e.g. $f_{x_2, x_4}(x_2, x_4)$
	- Integrate out everything that's not the thing you're interested in.

# Jointly Distributed Random Variables with One Discrete and One Continuous
- Ex: $P_{N, X}(n, x) = n(\frac{1}{2})^n e^{-nx}$ for $n = 1, 2, 3, \dots$, $x > 0$
	- Intuition: Flipping a balanced coin $n$ times. If N = n, win $X \sim$ exp(n).
	- pmf in first variable
	- pdf in second variable
	- Just called a "joint distribution"
	- Find the marginal of $X$.
	-
	\begin{align*}
		f_X(x) &= \sum\limits_{n = 1}^{\infty} n(\frac{e^{-x}}{2})^n \\
		&= \dots \\
		&= \frac{e^{-\frac{x}{2}}}{(1 - e^{-\frac{x}{2}})^2} \text{  For } x > 0
	\end{align*}
	- $P_N(n) = (\frac{1}{2})^n$ for $n = 1, 2, \dots$

# Independence
- $X_1, X_2, \dots X_n$ jointly distributed random variables
- We'll say they are independent if joint distribution = $\prod\limits_{i = 1}^n$ marginal distribution
	- $p(x_1, x_2, \dots x_n) = P_{X_1}(x_1)P_{X_2}(x_2) \dots P_{X_n}(x_n)$ $\forall$ $x_1, x_2, \dots x_n$
- Back to the beginning: 
	- Lost notes
